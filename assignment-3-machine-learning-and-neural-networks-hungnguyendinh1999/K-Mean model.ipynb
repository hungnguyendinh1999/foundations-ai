{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2db9ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from collections import defaultdict\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances , _euclidean_distances\n",
    "import numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f30c8ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# Load Dataset\n",
    "#################################################################\n",
    "\n",
    "dataset = fetch_20newsgroups(\n",
    "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
    "    subset=\"all\",\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")\n",
    "# categories = [\n",
    "#     \"alt.atheism\",\n",
    "#     \"talk.religion.misc\",\n",
    "#     \"comp.graphics\",\n",
    "#     \"sci.space\",\n",
    "# ]\n",
    " \n",
    "# dataset = fetch_20newsgroups(\n",
    "#     remove=(\"headers\", \"footers\", \"quotes\"),\n",
    "#     subset=\"all\",\n",
    "#     categories=categories,\n",
    "#     shuffle=True,\n",
    "#     random_state=42,\n",
    "# )\n",
    " \n",
    "\n",
    "labels = dataset.target\n",
    "unique_labels, category_sizes = np.unique(labels, return_counts=True)\n",
    "true_k = unique_labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c72994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.shape  (18846,)\n",
      "unique_labels.shape  (20,)\n",
      "category_sizes.shape  (20,)\n",
      "true_k  20\n"
     ]
    }
   ],
   "source": [
    "print(\"labels.shape \", labels.shape)\n",
    "print(\"unique_labels.shape \", unique_labels.shape)\n",
    "print(\"category_sizes.shape \", category_sizes.shape)\n",
    "print(\"true_k \", true_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a322da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# Vectorize \n",
    "#################################################################\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.5,\n",
    "    min_df=5,\n",
    "    stop_words=\"english\",\n",
    ")\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a364d730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18846"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75688b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# Evaluate Fitness\n",
    "#################################################################\n",
    "def fit_and_evaluate(km, X, n_runs=5):\n",
    "\n",
    "    scores = defaultdict(list)\n",
    "    for seed in range(n_runs):\n",
    "        km.set_params(random_state=seed)\n",
    "        km.fit(X)\n",
    "        scores[\"Homogeneity\"].append(metrics.homogeneity_score(labels, km.labels_))\n",
    "        scores[\"Completeness\"].append(metrics.completeness_score(labels, km.labels_))\n",
    "        scores[\"V-measure\"].append(metrics.v_measure_score(labels, km.labels_))\n",
    "        scores[\"Adjusted Rand-Index\"].append(\n",
    "            metrics.adjusted_rand_score(labels, km.labels_)\n",
    "        )\n",
    "        scores[\"Silhouette Coefficient\"].append(\n",
    "            metrics.silhouette_score(X, km.labels_, sample_size=2000)\n",
    "        )\n",
    "    for score_name, score_values in scores.items():\n",
    "        mean_score, std_score = np.mean(score_values), np.std(score_values)\n",
    "        print(f\"{score_name}: {mean_score:.3f} ± {std_score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "178c5acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# (TODO): Implement K-Means  \n",
    "#################################################################\n",
    "\n",
    "def check_random_state(seed):\n",
    "    # check_random_state from sklearn.utils\n",
    "    if seed is None or seed is np.random:\n",
    "        return np.random.mtrand._rand\n",
    "    if isinstance(seed, numbers.Integral):\n",
    "        return np.random.RandomState(seed)\n",
    "\n",
    "class KMeans:\n",
    "    labels_ = [] # predicted labels (y)\n",
    "    def __init__(self, n_clusters, max_iter=300):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "\n",
    "    def fit(self, X_train):\n",
    "        n_samples, n_features = X_train.shape\n",
    "        self.centroids = np.empty((self.n_clusters, n_features), dtype=X_train.dtype)\n",
    "\n",
    "        # Randomly select centroid\n",
    "        random_state = check_random_state(self.random_state)\n",
    "        center_id = random_state.choice(n_samples) # return an integer\n",
    "        self.centroids[0] = X_train[center_id].toarray() \n",
    "\n",
    "        # Initialize K (n_clusters) centroids #\n",
    "        for c in range(1, self.n_clusters):\n",
    "            # Calculate distances from points to the centroids\n",
    "            dists = np.sum(euclidean_distances(self.centroids, X_train), axis=0)\n",
    "            dists = dists/np.sum(dists) # Normalize the distances\n",
    "            # Choose remaining points based on their distances\n",
    "            new_centroid_idx = random_state.choice(n_samples, size=1, p=dists)\n",
    "            self.centroids[c] = X_train[new_centroid_idx].toarray()\n",
    "            \n",
    "        # Iterate, adjust centroids until converged or until passed max_iter\n",
    "        iteration = 0\n",
    "        prev_centroids = None\n",
    "        while np.not_equal(self.centroids, prev_centroids).any() and (iteration < self.max_iter):\n",
    "            # Assigning vector to nearest centroid #\n",
    "            dists = euclidean_distances(self.centroids, X_train)\n",
    "            centroid_idx = np.argmin(dists, axis=0)\n",
    "                \n",
    "            # Save current centroids\n",
    "            prev_centroids = self.centroids\n",
    "            \n",
    "            # Update centroids by mean of cluster #\n",
    "            new_centroids = np.empty((self.n_clusters, n_features), dtype=X_train.dtype)\n",
    "            for i in range(self.n_clusters):\n",
    "                cluster_i = X_train[centroid_idx == i]\n",
    "                if cluster_i.size == 0: \n",
    "                    new_centroids[i] = prev_centroids[i]\n",
    "                else:\n",
    "                    new_centroids[i] = np.mean(cluster_i, axis=0)\n",
    "\n",
    "            # Reassign centroids to new centroids\n",
    "            self.centroids = new_centroids\n",
    "\n",
    "            iteration += 1\n",
    "        \n",
    "        # Now that's done, let's calculate the current labels\n",
    "        distances = euclidean_distances(self.centroids, X_train)\n",
    "        self.labels_ = np.argmin(distances, axis=0)\n",
    "        \n",
    "\n",
    "    def set_params(self, random_state):\n",
    "        self.random_state = random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3cd60d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.276 ± 0.018\n",
      "Completeness: 0.329 ± 0.017\n",
      "V-measure: 0.300 ± 0.017\n",
      "Adjusted Rand-Index: 0.076 ± 0.012\n",
      "Silhouette Coefficient: 0.001 ± 0.003\n"
     ]
    }
   ],
   "source": [
    "# init K-Means\n",
    "kmeans = KMeans(n_clusters=true_k, max_iter=10)\n",
    "fit_and_evaluate(kmeans, X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7575000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.171 ± 0.100\n",
      "Completeness: 0.395 ± 0.037\n",
      "V-measure: 0.218 ± 0.087\n",
      "Adjusted Rand-Index: 0.046 ± 0.026\n",
      "Silhouette Coefficient: 0.005 ± 0.003\n"
     ]
    }
   ],
   "source": [
    "# Test with actual KMeans performance class\n",
    "from sklearn.cluster import KMeans as real_KMeans\n",
    "real_kmeans = real_KMeans(init=\"k-means++\", n_clusters=true_k, n_init=4)\n",
    "\n",
    "fit_and_evaluate(real_kmeans, X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94430ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18846, 24164)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "853afbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24164,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.centroids[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4d861d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.40558583, 1.40418857, 1.39503057, ..., 1.41421356, 1.39731476,\n",
       "        1.38785215],\n",
       "       [1.19463731, 1.19463731, 1.18892012, ..., 1.19463731, 1.19463731,\n",
       "        1.18187191],\n",
       "       [1.05513771, 1.0732083 , 1.06971876, ..., 1.0732083 , 1.0732083 ,\n",
       "        1.0732083 ],\n",
       "       [1.06920505, 1.06920505, 1.06390841, ..., 1.06920505, 1.06920505,\n",
       "        1.06920505]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = euclidean_distances(kmeans.centroids, X_tfidf)\n",
    "dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d40b0317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3387)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a164a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = np.sum(dists, axis=0)\n",
    "dists = dists / np.sum(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "808a9a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.40558583, 1.40418857, 1.39503057, ..., 1.41421356, 1.39731476,\n",
       "        1.38785215],\n",
       "       [1.19463731, 1.19463731, 1.18892012, ..., 1.19463731, 1.19463731,\n",
       "        1.18187191],\n",
       "       [1.05513771, 1.0732083 , 1.06971876, ..., 1.0732083 , 1.0732083 ,\n",
       "        1.0732083 ],\n",
       "       [1.06920505, 1.06920505, 1.06390841, ..., 1.06920505, 1.06920505,\n",
       "        1.06920505]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a516a48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3369"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(range(X_tfidf.shape[0]), p=dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "db044a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3387,)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid_idx = np.argmin(dists, axis=0)\n",
    "centroid_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "dedf1b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7929,)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_tfidf[centroid_idx == 2], axis=0).A1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "22df543d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7929)\n",
      "(0, 7929)\n",
      "(313, 7929)\n",
      "(3073, 7929)\n"
     ]
    }
   ],
   "source": [
    "for ind in range(4):\n",
    "    m = X_tfidf[centroid_idx == ind]\n",
    "    print(m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7a1fcb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: threadpoolctl\r\n",
      "Version: 2.2.0\r\n",
      "Summary: threadpoolctl\r\n",
      "Home-page: https://github.com/joblib/threadpoolctl\r\n",
      "Author: Thomas Moreau\r\n",
      "Author-email: thomas.moreau.2010@gmail.com\r\n",
      "License: BSD-3-Clause\r\n",
      "Location: /Users/hungnguyen/opt/anaconda3/lib/python3.8/site-packages\r\n",
      "Requires: \r\n",
      "Required-by: imbalanced-learn, scikit-learn\r\n"
     ]
    }
   ],
   "source": [
    "!pip show threadpoolctl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a6751c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import threadpoolctl\n",
    "threadpoolctl.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9cc460",
   "metadata": {},
   "source": [
    "# 1.1 ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b58bb85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "150c9cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "v1 = np.array([0.79, -0.14, -0.13, -0.24, -0.4])\n",
    "v2 = np.array([-0.77, 0.76, 0.78, -0.51, -0.92])\n",
    "bv1 = 0.02\n",
    "bv2 = -0.01\n",
    "\n",
    "w1 = np.array([0.8, 0.58])\n",
    "w2 = np.array([0.18, 0.32])\n",
    "w3 = np.array([0.94, -0.24])\n",
    "bw1 = 0\n",
    "bw2 = 0.01\n",
    "bw3 = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e27b144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    if x > 0:\n",
    "        return (x + abs(x))/2\n",
    "    else: return 0\n",
    "\n",
    "# Faster method\n",
    "def ReLuLu(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "# Sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3a42474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment setup\n",
    "# sigmoids represent labels [0, 1, 2]\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y_true = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebde787f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5\n",
      "1 0.5024999791668749\n",
      "2 0.5074994375506203\n"
     ]
    }
   ],
   "source": [
    "# Forward pass #\n",
    "# Output of layer \"v\"\n",
    "out_v1 = np.dot(x, v1) + bv1 # negative num\n",
    "out_v1 = ReLU(out_v1)\n",
    "\n",
    "out_v2 = np.dot(x, v2) + bv2 # negative num\n",
    "out_v2 = ReLU(out_v2)\n",
    "\n",
    "# Output of layer \"w\"\n",
    "x_layer_v = np.array([out_v1, out_v2])\n",
    "\n",
    "out_w1 = np.dot(x_layer_v, w1) + bw1\n",
    "out_w1 = sigmoid(out_w1)\n",
    "\n",
    "out_w2 = np.dot(x_layer_v, w2) + bw2\n",
    "out_w2 = sigmoid(out_w2)\n",
    "\n",
    "out_w3 = np.dot(x_layer_v, w3) + bw3\n",
    "out_w3 = sigmoid(out_w3)\n",
    "\n",
    "pred_y = np.array([out_w1, out_w2, out_w3])\n",
    "for i,val in enumerate(pred_y):\n",
    "    print(i, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4655e028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6881596805078625"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate log loss\n",
    "def L(x, y):\n",
    "    return np.dot(-y, np.log(pred_y))\n",
    "\n",
    "L(pred_y, np.array([0, y_true, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02836192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2ea29c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.82 -3.56]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output of layer \"v\"\n",
    "out_v = np.dot(np.array([v1, v2]), x) + np.array([bv1, bv2])\n",
    "print(out_v)\n",
    "out_v = np.vectorize(ReLU)(out_v)\n",
    "\n",
    "# Output of layer \"w\"\n",
    "out_w = np.dot(np.array([w1, w2, w3]), out_v) + np.array([bw1, bw2, bw3])\n",
    "print(out_w)\n",
    "out_w = np.vectorize(sigmoid)(out_w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74585c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.84, -3.55])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(x , np.array([v1, v2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861e57ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
